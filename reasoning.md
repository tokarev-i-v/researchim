## **Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though**

https://arxiv.org/abs/2501.04682

### **1. Введение (Introduction)**

#### **Мотивация: Почему нужно Meta-CoT?**
- Современные большие языковые модели (LLMs) основываются на предсказании следующего токена (next-token prediction), что позволяет им успешно решать множество задач. Однако их возможности ограничены при решении задач с высокой степенью сложности.
- Для улучшения сложного мышления в LLMs часто используется метод Chain-of-Thought (CoT), который помогает моделям размышлять пошагово. Например, для решения математической задачи модель может сначала разложить задачу на простые шаги, что уже улучшает её производительность.
- **Проблема**: CoT не отражает сложные, нелинейные процессы мышления, особенно те, которые включают поиск, проверку промежуточных решений и корректировку курса. Такие задачи требуют "мышления второго уровня" (System 2 Reasoning), что ближе к человеческому интеллекту.

#### **Цель исследования:**
- Ввести концепцию **Meta-CoT**, которая моделирует скрытые процессы мышления (например, поиск, верификацию и корректировку).
- Разработать теоретический и практический подход к обучению моделей с Meta-CoT.

---

### **2. Что такое Meta Chain-of-Thought (Meta-CoT)?**

#### **2.1. Почему традиционный CoT не всегда работает?**
- **Традиционный CoT** строится на линейном, пошаговом подходе: модель генерирует последовательность шагов (S1, S2, ...), которая приводит к ответу (A). Однако:
  - Этот процесс часто упрощает реальный способ решения сложных задач.
  - На сложных задачах, таких как математические олимпиады, требуется рассуждение, включающее промежуточные скрытые шаги или проверку, что CoT не учитывает.
  - Пример: сложная задача может включать шаги поиска, где модель должна "пробовать" разные гипотезы, возвращаться назад (backtracking) и корректировать решения, чего CoT не делает.

#### **2.2. Концепция Meta-CoT**
- **Meta-CoT** добавляет скрытые состояния ("промежуточные мысли") между шагами решения задачи. Это позволяет моделировать процессы, такие как:
  - Поиск новых решений.
  - Проверка правильности промежуточных шагов.
  - Возврат назад (backtracking) при обнаружении ошибок.
- Формально, Meta-CoT можно выразить как:
  ```math
  P(answer, steps | question) = ∫ P(answer, steps | hidden_states, question) * P(hidden_states | question)
  ```
  Это подчеркивает, что ответ и шаги решения зависят от скрытых состояний (hidden_states), которые моделируются отдельно.

---

### **3. Алгоритмы поиска и их связь с Meta-CoT**

#### **3.1. Почему поиск важен для Meta-CoT?**
- Многие задачи высокого уровня сложности (например, математические доказательства) требуют **процесса поиска**, где модель:
  - Формирует гипотезы.
  - Проверяет их правильность.
  - Корректирует курс при ошибках.
- Поиск позволяет моделям использовать больше вычислительных ресурсов во время вывода (inference), что улучшает производительность.

#### **3.2. Алгоритмы поиска:**
- **Monte Carlo Tree Search (MCTS):**
  - Используется для построения дерева поиска, где каждый узел — это промежуточное состояние, а модель оценивает вероятность успеха для каждого пути.
  - Это позволяет эффективно изучать множество вариантов решений.
- **A* Search:**
  - Основан на оценке стоимости пути (cost) и эвристике, которая прогнозирует, насколько решение близко к цели.
  - Применим для задач, где важны точные и минимально затратные решения.

#### **3.3. Примеры применения поиска:**
- В статье приводятся эксперименты, показывающие, что использование MCTS и A* позволяет обучать модели эффективно решать сложные задачи. Например:
  - Задачи из соревнований по математике (MATH Dataset).
  - Игры, требующие стратегического мышления (например, шахматы).

---

### **4. Обучение Meta-CoT**

#### **4.1. Как обучать модель работать с Meta-CoT?**
- Meta-CoT требует специального подхода к обучению, который включает:
  1. **Процесс-супервизию (Process Supervision):**
     - Вместо обучения только на финальных ответах, модель обучается всему процессу решения задачи, включая промежуточные шаги.
  2. **Синтетические данные для поиска:**
     - Используются алгоритмы, такие как MCTS, чтобы генерировать обучающие данные, которые моделируют поиск и проверку.
  3. **Тонкая настройка инструкций (Instruction Tuning):**
     - Обучение модели с использованием заранее подготовленных пошаговых решений.
  4. **Реинфорсмент-обучение (Reinforcement Learning):**
     - После базового обучения модель дообучается с использованием методов RL, чтобы улучшить способность к корректировке ошибок.

#### **4.2. Методы генерации данных:**
- **STaR (Self-Taught Reasoner):**
  - Модель сначала генерирует шаги решения задачи, затем проверяет, правильно ли она пришла к ответу. Если ответ правильный, модель сохраняет эти шаги и дообучается на них.
- **Meta-STaR:**
  - Расширение STaR, которое включает нелинейные шаги поиска и проверки.

---

### **5. Эксперименты и результаты**

#### **5.1. Задачи и данные:**
- Использовались сложные наборы данных, такие как:
  - **MATH Dataset:** математические задачи, требующие сложного мышления.
  - **HARP Benchmark:** задачи высокого уровня сложности, например, задачи из олимпиад.

#### **5.2. Результаты:**
- Модели с Meta-CoT превосходят традиционные CoT по точности на сложных задачах.
- Пример: Для сложных математических задач модели с Meta-CoT показали до 20% прироста точности по сравнению с обычным CoT.

---

### **6. Выводы и открытые вопросы**

#### **6.1. Основные выводы:**
- Meta-CoT значительно расширяет возможности LLMs, позволяя им решать задачи, недоступные традиционным методам.
- Этот подход сочетает теорию (понимание скрытых процессов мышления) и практику (алгоритмы поиска, обучение с супервизией и RL).

#### **6.2. Открытые вопросы:**
- Как масштабировать Meta-CoT для еще более сложных задач?
- Какая роль верификаторов (моделей проверки) в обучении и выводе?
- Возможно ли открыть новые алгоритмы мышления через обучение Meta-CoT?

---

Если вы хотите, я могу подробнее рассмотреть конкретные разделы или объяснить отдельные методы (например, MCTS или Meta-STaR).
